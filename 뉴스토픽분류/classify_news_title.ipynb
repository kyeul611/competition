{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertModel, TFBertModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string],\"\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed 고정\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN = 44 # EDA에서 추출된 max Lenght => EDA: 탐색적 데이터분석\n",
    "DATA_IN_PATH = 'data_in/open/'\n",
    "DATA_OUT_PATH = 'data_out'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_IN_PATH + \"train_data.csv\")\n",
    "test_data = pd.read_csv(DATA_IN_PATH + \"test_data.csv\")\n",
    "submission = pd.read_csv(DATA_IN_PATH + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent,\n",
    "        add_special_tokens = True,  # Add [CLS] + [SEP]\n",
    "        max_length = MAX_LEN,       # Pad & truncate all sentences(truncate: 길이를 줄이다.)\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True #Construct attn masks \n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask'] # And its attention mask (simply differentiates padding from non-padding).\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25316</th>\n",
       "      <td>25316</td>\n",
       "      <td>중국 매체들 홍콩시위 옹호 영국 맹비난</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21401</th>\n",
       "      <td>21401</td>\n",
       "      <td>리뷰 우리는 진정 해방됐나…뮤지컬 아리랑</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12383</th>\n",
       "      <td>12383</td>\n",
       "      <td>브렉시트 수렁에 빠진 英정부 조기총선 놓고도 갑론을박</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28685</th>\n",
       "      <td>28685</td>\n",
       "      <td>2분기도 수출 회복 어렵다…반도체마저 나빠질듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28951</th>\n",
       "      <td>28951</td>\n",
       "      <td>인공지능에 얼굴인식까지…미래 스마트폰 갤럭시S8종합</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                          title  topic_idx\n",
       "25316  25316          중국 매체들 홍콩시위 옹호 영국 맹비난          4\n",
       "21401  21401         리뷰 우리는 진정 해방됐나…뮤지컬 아리랑          3\n",
       "12383  12383  브렉시트 수렁에 빠진 英정부 조기총선 놓고도 갑론을박          4\n",
       "28685  28685      2분기도 수출 회복 어렵다…반도체마저 나빠질듯          1\n",
       "28951  28951   인공지능에 얼굴인식까지…미래 스마트폰 갤럭시S8종합          0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>52472</td>\n",
       "      <td>하반기 경제 중도금 대출 규제 분양시장 냉각 우려</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>51642</td>\n",
       "      <td>전직 대법관 영장기각 항의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>52647</td>\n",
       "      <td>북한 핵실험 날 주민 2명 압록강 건너 탈북했다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>51876</td>\n",
       "      <td>카카오 7천544억 규모 유증…로엔엔터 지분 취득</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>47190</td>\n",
       "      <td>경기 8개 시·군 호우주의보…장마 영향 호우특보 확대</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                          title\n",
       "6818  52472    하반기 경제 중도금 대출 규제 분양시장 냉각 우려\n",
       "5988  51642                 전직 대법관 영장기각 항의\n",
       "6993  52647     북한 핵실험 날 주민 2명 압록강 건너 탈북했다\n",
       "6222  51876    카카오 7천544억 규모 유증…로엔엔터 지분 취득\n",
       "1536  47190  경기 8개 시·군 호우주의보…장마 영향 호우특보 확대"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>48834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>46572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>48651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>51516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  topic_idx\n",
       "3180  48834          0\n",
       "3946  49600          0\n",
       "918   46572          0\n",
       "2997  48651          0\n",
       "5862  51516          0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/45654 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\kyeul\\anaconda3\\envs\\tf2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 45654/45654 [00:07<00:00, 5782.76it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "train_data_labels = []\n",
    "\n",
    "for train_sent, train_label in tqdm(zip(train_data[\"title\"], train_data['topic_idx']), total=len(train_data)):\n",
    "    \n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(train_sent, MAX_LEN)\n",
    "    \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        train_data_labels.append(train_label)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(train_sent)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 45654, # labels: 45654\n"
     ]
    }
   ],
   "source": [
    "train_sent_input_ids = np.array(input_ids, dtype=int)\n",
    "train_sent_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_sent_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_sent_inputs = (train_sent_input_ids, train_sent_attention_masks, train_sent_type_ids)\n",
    "\n",
    "train_data_labels = np.asarray(train_data_labels, dtype=np.int32)\n",
    "\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(train_sent_input_ids), len(train_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
