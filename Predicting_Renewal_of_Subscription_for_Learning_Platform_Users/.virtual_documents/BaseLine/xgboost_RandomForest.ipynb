


import pandas as pd


train = pd.read_csv('../data/train.csv')
test = pd.read_csv('../data/test.csv')


train.info()


info = pd.read_csv('../data/data_info.csv')
info


train.head()


train.shape, test.shape


train.isnull().sum()


test.isnull().sum()


# 타겟 비율 확인
train['target'].value_counts() 
## unbalance 하네.


# 수치형 변수 기초 통계
train.describe()


# 범주형 변수 기초 통계
display(train.describe(include='O'))
display(test.describe(include='O'))


train['preferred_difficulty_level'].value_counts()


train['preferred_difficulty_level'].value_counts(normalize=True)


train['subscription_type'].value_counts()





# user_id 제거
train.pop('user_id')
test_user_id = test.pop('user_id')


target = train.pop('target')


# encoding
train = pd.get_dummies(train)
test = pd.get_dummies(test)


train.head(5)


# split data to train_set and valid_set

from sklearn.model_selection import train_test_split
x_train, x_valid, y_train, y_valid = train_test_split(train, target, test_size=0.2, random_state=42)


# 모델링 (random forest)
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100)
rf.fit(x_train, y_train)
pred_rf = rf.predict(x_valid)


# 모델링 (xgboost)
from xgboost import XGBClassifier
xgb = XGBClassifier(random_state=42, n_estimators=300, max_depth=5)
xgb.fit(x_train, y_train)
pred_xgb = xgb.predict(x_valid)





from sklearn.metrics import f1_score


# rf 평가
f1_score(y_valid, pred_rf, average='macro')


# xgboost 평가
f1_score(y_valid, pred_xgb, average='macro')





result = xgb.predict(test)
submit = pd.DataFrame({
    'user_id': test_user_id,
    'target': result
})

submit.to_csv("xgb-n_300-maxDepth_5.csv", index=False)



