{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838250cc-244f-4e8d-8dd5-907caa017038",
   "metadata": {},
   "source": [
    "From : [링크](https://dacon.io/competitions/official/235747/codeshare/3047?page=2&dtype=recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0473bb-0bc3-4089-bf60-43bc5c4c5957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyeul\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import wandb\n",
    "\n",
    "# warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eecf1cb-1b2e-4f27-ab81-5d39f778a3b0",
   "metadata": {},
   "source": [
    "klue/bert-base 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8fa436-c7ed-46ab-9193-14c106b4cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgyul611\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Kyeul\\Desktop\\code\\competition\\news_topic_classification\\boong_u.klue-bert\\wandb\\run-20231128_181045-mtj5pnkj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gyul611/boong_u__klue-ynat_classification/runs/mtj5pnkj' target=\"_blank\">fast-waterfall-5</a></strong> to <a href='https://wandb.ai/gyul611/boong_u__klue-ynat_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gyul611/boong_u__klue-ynat_classification' target=\"_blank\">https://wandb.ai/gyul611/boong_u__klue-ynat_classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gyul611/boong_u__klue-ynat_classification/runs/mtj5pnkj' target=\"_blank\">https://wandb.ai/gyul611/boong_u__klue-ynat_classification/runs/mtj5pnkj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gyul611/boong_u__klue-ynat_classification/runs/mtj5pnkj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x26e059aad50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='boong_u__klue-ynat_classification',\n",
    "    entity='gyul611',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e784e842-8836-4cb9-b305-8780051a0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'klue/bert-base'\n",
    "batch_size=512+256\n",
    "task='nli' # 자연어 추론\n",
    "RANDOM_SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a3a5bb-5f62-4a1e-8f20-ae1834ed5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b6451b-5b00-4c94-9fa4-efca5bcdf67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data/train_data.csv\")\n",
    "test = pd.read_csv(\"../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a4f5a17-fc59-4b2d-a1a9-0aa745e4f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val = train_test_split(dataset, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c785331-eaaf-452e-8eea-937a238c216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_key, label_key, bert_tokenizer):\n",
    "        self. sentences = [bert_tokenizer(i, truncation=True, return_token_type_ids=False) for i in dataset[sent_key]]\n",
    "\n",
    "        # ? 왜 이렇게 하는 거지\n",
    "\n",
    "        # label이 있으면 train 모드\n",
    "        # 없으면 test 모드\n",
    "        if not label_key == None:\n",
    "            self.mode = \"train\"\n",
    "        else:\n",
    "            self.mode = \"test\"\n",
    "\n",
    "        # label 매핑?\n",
    "        if self.mode == \"train\":\n",
    "            self.labels = [np.int64(i) for i in dataset[label_key]]\n",
    "        else:\n",
    "            self.labels = [np.int64(0) for i in dataset[sent_key]]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.mode == \"train\":\n",
    "            self.sentences[i]['label'] = self.labels[i]\n",
    "            return self.sentences[i]\n",
    "\n",
    "        else:\n",
    "            return self.sentences[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617babbb-48e1-44cd-a816-eab08eb12430",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, \"title\", \"topic_idx\", tokenizer)\n",
    "data_val = BERTDataset(dataset_val, \"title\", \"topic_idx\", tokenizer)\n",
    "data_test = BERTDataset(test, \"title\", None, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c592f0c6-31ed-4f8f-a4f4-e50ea37a3274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 7\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba5bb26-18e5-45e3-8f3a-d7c7abbae4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"glue\", \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "465cda32-b981-43ef-8c22-d5aa5c58d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "143ae023-20fb-4ebd-b192-6dc6c88edc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    'test-nli',\n",
    "    save_total_limit=5,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    report_to='wandb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea3ffad-7a3b-483d-9763-33f3a129806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_search를 위해서는 model_init을 만들어야함.\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922a4deb-fd04-42b2-9231-b18760e31bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776df403-fe64-456b-9e64-3f24b4822054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 18:11:02,837] A new study created in memory with name: no-name-229d4ca8-f7cb-47ba-9f08-1137b59f99dd\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-waterfall-5</strong> at: <a href='https://wandb.ai/gyul611/boong_u__klue-ynat_classification/runs/mtj5pnkj' target=\"_blank\">https://wandb.ai/gyul611/boong_u__klue-ynat_classification/runs/mtj5pnkj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231128_181045-mtj5pnkj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Kyeul\\Desktop\\code\\competition\\news_topic_classification\\boong_u.klue-bert\\wandb\\run-20231128_181111-fdokzolm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gyul611/huggingface/runs/fdokzolm' target=\"_blank\">blooming-terrain-16</a></strong> to <a href='https://wandb.ai/gyul611/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gyul611/huggingface' target=\"_blank\">https://wandb.ai/gyul611/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gyul611/huggingface/runs/fdokzolm' target=\"_blank\">https://wandb.ai/gyul611/huggingface/runs/fdokzolm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2855' max='2855' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2855/2855 03:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.602700</td>\n",
       "      <td>0.346917</td>\n",
       "      <td>0.884898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.322956</td>\n",
       "      <td>0.891907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.320853</td>\n",
       "      <td>0.893330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.270100</td>\n",
       "      <td>0.317120</td>\n",
       "      <td>0.893988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>0.316513</td>\n",
       "      <td>0.896178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 18:15:04,399] Trial 0 finished with value: 0.8961778556565546 and parameters: {'learning_rate': 6.931763037713002e-06, 'num_train_epochs': 5, 'seed': 23, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 0.8961778556565546.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆▇█</td></tr><tr><td>eval/loss</td><td>█▂▂▁▁</td></tr><tr><td>eval/runtime</td><td>▆█▁▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▃▁█▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▃▁█▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.89618</td></tr><tr><td>eval/loss</td><td>0.31651</td></tr><tr><td>eval/runtime</td><td>2.95</td></tr><tr><td>eval/samples_per_second</td><td>3095.281</td></tr><tr><td>eval/steps_per_second</td><td>4.068</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>2855</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2425</td></tr><tr><td>train/total_flos</td><td>2138790628652250.0</td></tr><tr><td>train/train_loss</td><td>0.33473</td></tr><tr><td>train/train_runtime</td><td>238.3652</td></tr><tr><td>train/train_samples_per_second</td><td>766.114</td></tr><tr><td>train/train_steps_per_second</td><td>11.977</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-terrain-16</strong> at: <a href='https://wandb.ai/gyul611/huggingface/runs/fdokzolm' target=\"_blank\">https://wandb.ai/gyul611/huggingface/runs/fdokzolm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231128_181111-fdokzolm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Kyeul\\Desktop\\code\\competition\\news_topic_classification\\boong_u.klue-bert\\wandb\\run-20231128_181511-oba72zsz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gyul611/huggingface/runs/oba72zsz' target=\"_blank\">playful-terrain-17</a></strong> to <a href='https://wandb.ai/gyul611/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gyul611/huggingface' target=\"_blank\">https://wandb.ai/gyul611/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gyul611/huggingface/runs/oba72zsz' target=\"_blank\">https://wandb.ai/gyul611/huggingface/runs/oba72zsz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5710' max='5710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5710/5710 05:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.328187</td>\n",
       "      <td>0.890483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.317756</td>\n",
       "      <td>0.893002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.321151</td>\n",
       "      <td>0.895849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.322583</td>\n",
       "      <td>0.897821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.331204</td>\n",
       "      <td>0.897711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 18:20:33,047] Trial 1 finished with value: 0.8977110940751287 and parameters: {'learning_rate': 8.17142456246069e-06, 'num_train_epochs': 5, 'seed': 35, 'per_device_train_batch_size': 32}. Best is trial 1 with value: 0.8977110940751287.\n"
     ]
    }
   ],
   "source": [
    "best_run = trainer.hyperparameter_search(n_trials=2, direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f56a289-dd15-4a91-ab33-c464b256d99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='1', objective=0.8977110940751287, hyperparameters={'learning_rate': 8.17142456246069e-06, 'num_train_epochs': 5, 'seed': 35, 'per_device_train_batch_size': 32}, run_summary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c11d91-dc4b-4a43-a98e-8e3ced39469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5710' max='5710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5710/5710 05:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.328187</td>\n",
       "      <td>0.890483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.317756</td>\n",
       "      <td>0.893002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.321151</td>\n",
       "      <td>0.895849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.322583</td>\n",
       "      <td>0.897821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.331204</td>\n",
       "      <td>0.897711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5710, training_loss=0.2858988927249942, metrics={'train_runtime': 316.8462, 'train_samples_per_second': 576.352, 'train_steps_per_second': 18.021, 'total_flos': 2056542634442700.0, 'train_loss': 0.2858988927249942, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb8ceba3-1930-461e-b60a-4b3608f99130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3225833475589752,\n",
       " 'eval_accuracy': 0.8978206111050269,\n",
       " 'eval_runtime': 2.9511,\n",
       " 'eval_samples_per_second': 3094.069,\n",
       " 'eval_steps_per_second': 4.066,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate() # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f90de9e8-7314-4450-b7be-d892797508d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 1.7568895 ,  0.1507784 ,  2.1030583 , ..., -2.3661284 ,\n",
       "        -2.6856828 , -3.3943496 ],\n",
       "       [-1.8309041 , -2.0773034 ,  0.10060618, ..., -1.166829  ,\n",
       "        -1.552108  , -1.3320658 ],\n",
       "       [ 2.033948  ,  0.40936077,  4.301589  , ..., -2.6633341 ,\n",
       "        -2.5798059 , -0.5348093 ],\n",
       "       ...,\n",
       "       [-1.5713437 , -1.4163268 ,  3.2175384 , ..., -1.4705619 ,\n",
       "        -2.3041637 , -2.1479445 ],\n",
       "       [ 1.2939097 , -0.10006521,  4.077904  , ..., -2.964298  ,\n",
       "        -1.5077595 , -0.8723607 ],\n",
       "       [ 2.113509  , -0.9350316 ,  2.9323263 , ..., -2.2945492 ,\n",
       "        -2.0192602 ,  1.9491215 ]], dtype=float32), label_ids=None, metrics={'test_runtime': 2.9082, 'test_samples_per_second': 3139.737, 'test_steps_per_second': 4.126})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = trainer.predict(data_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1137047b-0ec3-43f7-879c-0ecc199db6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[0]\n",
    "pred = np.argmax(pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "577ee5b0-780d-4513-96ab-7864c52cf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "submission['topic_idx'] = pred\n",
    "submission.to_csv(\"klue-bert-base.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f682069-49a6-4632-9e16-4049dd4f024e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
