import pandas as pd
import re
from konlpy.tag import Okt, Mecab
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, f1_score
from lightgbm import LGBMClassifier





train = pd.read_csv('../data/train_data.csv')


# 데이터 확인
train.head()


# 결측치 확인
train.isnull().sum()


# label 분포 확인
train.topic_idx.value_counts()





okt = Okt()


train['title']


# 조사, 어미, 구두점 제거
def func(text):
    clean = []
    for word in okt.pos(text, stem=True): # 어간 추출
        if word[1] not in ['Josa', 'Eomi', 'Punctuation']: # 조사, 어미 , 구두점 제외
            clean.append(word[0])
    return " ".join(clean)

train['title'] = train['title'].apply(lambda x : func(x))


train['title']


# tf-idf를 이용한 vectorization
def split(text):
    tokens_ko = text.split()
    return tokens_ko

tfidf_vect = TfidfVectorizer(tokenizer=split)
tfidf_vect.fit(train['title'])
tfidf_matrix_train = tfidf_vect.transform(train['title'])


# train/valid 데이터셋 나누기
def split_dataset(tfidf, df):
    X_data = tfidf
    y_data = df['topic_idx']

    # stratify = y_data Stratified 기반 분할, train 데이터의 30%를 평가 데이터셋으로 사용.
    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42, stratify=y_data)

    return (X_train, X_test, y_train, y_test)


X_train, X_test, y_train, y_test = split_dataset(tfidf_matrix_train, train)





lgbm = LGBMClassifier()
lgbm.fit(X_train, y_train)





pred = lgbm.predict(X_test)
accuracy = accuracy_score(y_test, pred)

print("정확도: ", accuracy)





test = pd.read_csv('../data/test_data.csv')
test


test['title'] = test['title'].apply(lambda x : func(x))
tfidf_matrix_test = tfidf_vect.transform(test['title'])


pred = lgbm.predict(tfidf_matrix_test)


pred





submission = pd.read_csv('../data/sample_submission.csv')


submission['topic_idx']=pred
submission.head()


# save
submission.to_csv('baseline.csv', index=False)



